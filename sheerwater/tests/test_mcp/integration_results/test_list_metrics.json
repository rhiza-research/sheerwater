{
  "test_name": "test_list_metrics",
  "timestamp": "2026-02-12T10:56:41.616006",
  "prompt": "List available evaluation metrics using sheerwater",
  "response": "Here are the available evaluation metrics from Sheerwater:\n\n## Continuous Metrics\n\n| Metric | Full Name | Interpretation |\n|--------|-----------|----------------|\n| **acc** | Anomaly Correlation Coefficient | Higher is better (1.0 = perfect, 0.0 = no skill) |\n| **bias** | Bias | Closer to 0 is better; positive = over-prediction |\n| **mae** | Mean Absolute Error | Lower is better |\n| **mse** | Mean Squared Error | Lower is better; more sensitive to outliers |\n| **rmse** | Root Mean Squared Error | Lower is better; more sensitive to outliers |\n| **mape** | Mean Absolute Percentage Error | Lower is better (precip only) |\n| **smape** | Symmetric Mean Absolute Percentage Error | Lower is better (precip only) |\n| **pearson** | Pearson Correlation Coefficient | Higher is better (-1 to 1) |\n| **seeps** | Stable Equitable Error in Probability Space | Lower is better; designed for rainfall verification |\n\n## Categorical Metrics\n\n| Metric | Full Name | Interpretation |\n|--------|-----------|----------------|\n| **heidke** | Heidke Skill Score | Higher is better (0 = no skill, 1 = perfect) |\n| **pod** | Probability of Detection | Higher is better (hit rate) |\n| **far** | False Alarm Rate | Lower is better |\n| **ets** | Equitable Threat Score | Higher is better; balanced skill measure |\n| **csi** | Critical Success Index | Higher is better (Threat Score) |\n| **frequencybias** | Frequency Bias | 1.0 is ideal; >1 = over-forecasting |\n\n## Probabilistic Metrics\n\n| Metric | Full Name | Interpretation |\n|--------|-----------|----------------|\n| **crps** | Continuous Ranked Probability Score | Lower is better; measures calibration and sharpness |\n| **brier** | Brier Score | Lower is better (0 = perfect, 1 = worst) |\n\nUse `tool_get_metric_info` with a specific metric name for detailed formulas and usage guidance.\n",
  "success": true
}